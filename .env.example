# ========================================
# LEGO Assembly System - Environment Configuration
# ========================================
# Copy this file to .env and fill in your API keys

# ========================================
# API KEYS
# ========================================
# LiteLLM will automatically use the correct key based on the model you specify

# OpenAI (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google (for Gemini models)
GEMINI_API_KEY=your_gemini_api_key_here

# Alibaba Cloud DashScope (for Qwen models)
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# DeepSeek
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Moonshot (Kimi)
MOONSHOT_API_KEY=your_moonshot_api_key_here

# ========================================
# API ENDPOINTS (Optional - uses defaults if not specified)
# ========================================
QWEN_VL_ENDPOINT=https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation
DEEPSEEK_ENDPOINT=https://api.deepseek.com/v1
MOONSHOT_ENDPOINT=https://api.moonshot.cn/v1
OPENAI_ENDPOINT=https://api.openai.com/v1
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models

# ========================================
# PHASE 1: VLM SELECTION FOR INGESTION
# ========================================
# Used for extracting steps from instruction manual pages
# LiteLLM naming convention: "provider/model" or just "model" for OpenAI
#
# Popular choices:
#   Gemini: gemini/gemini-2.5-flash, gemini/gemini-robotics-er-1.5-preview
#   OpenAI: gpt-4o, gpt-4o-mini, gpt-4-vision-preview
#   Claude: claude-3-5-sonnet-20241022, claude-3-opus-20240229
#   Qwen: dashscope/qwen-vl-max, dashscope/qwen-vl-plus

INGESTION_VLM=gemini/gemini-2.5-flash
INGESTION_SECONDARY_VLM=gpt-4o-mini
INGESTION_FALLBACK_VLM=dashscope/qwen-vl-max

# ========================================
# BACKEND: VLM FOR MULTIMODAL PROCESSING
# ========================================
# Used for generating rich descriptions of instruction diagrams

DIAGRAM_VLM=gemini/gemini-2.5-flash

# ========================================
# LLM SETTINGS FOR RAG PIPELINE
# ========================================
# Model used for generating text responses
#
# Popular choices:
#   OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
#   Gemini: gemini/gemini-2.5-flash, gemini/gemini-pro
#   Qwen: dashscope/qwen-max, dashscope/qwen-plus
#   DeepSeek: deepseek/deepseek-chat

RAG_LLM_MODEL=gemini/gemini-2.5-flash

# ========================================
# EMBEDDING SETTINGS
# ========================================
# Models used for generating vector embeddings
#
# For multimodal embeddings (combines text + image descriptions):
EMBEDDING_VLM=gemini/gemini-2.5-flash
#
# For vector database embeddings (retrieval):
# Popular choices:
#   OpenAI: text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002
#   Gemini: gemini/text-embedding-004
#   Cohere: embed-english-v3.0
#   Qwen: dashscope/text-embedding-v2

RAG_EMBEDDING_MODEL=gemini/text-embedding-004

# ========================================
# MODEL-SPECIFIC SETTINGS
# ========================================
# Legacy compatibility - use LiteLLM model names above instead
GEMINI_MODEL=gemini/gemini-2.5-flash
OPENAI_MODEL=gpt-4o-mini

# ========================================
# SYSTEM CONFIGURATION
# ========================================

# Cache settings
CACHE_DIR=./cache
CACHE_ENABLED=true
MAX_RETRIES=3
REQUEST_TIMEOUT=120

# Part database
PARTS_DB_PATH=./data/parts_database.db
REBRICKABLE_API_KEY=your_rebrickable_api_key_here

# ========================================
# ROBOFLOW SAM3 - SEGMENTATION API
# ========================================
# Get your API key from: https://app.roboflow.com/settings/api
# SAM3 (Segment Anything Model 3) provides text-prompt based segmentation
# for extracting LEGO parts and assembled results from instruction images

# Enable/disable SAM3 segmentation
ENABLE_ROBOFLOW_SAM3=false

# API Configuration
ROBOFLOW_API_KEY=your_roboflow_api_key_here

# SAM3 Segmentation Settings
ROBOFLOW_SAM3_CONFIDENCE_THRESHOLD=0.7
ROBOFLOW_SAM3_OUTPUT_DIR=./output/segmented_parts
ROBOFLOW_SAM3_SAVE_MASKS=true
ROBOFLOW_SAM3_SAVE_CROPPED_IMAGES=true
ROBOFLOW_SAM3_OUTPUT_FORMAT=json

# ========================================
# SAM (Segment Anything Model) SETTINGS
# ========================================
# Enable/disable SAM-based component extraction
ENABLE_SAM=true

# SAM model selection
# Options: sam2_b (base), sam2_l (large), sam2_s (small), sam2_t (tiny)
# Larger models = better accuracy, slower processing
# Recommended: sam2_b for balance of speed and accuracy
SAM_MODEL=sam2_b

# SAM confidence threshold (0.0 to 1.0)
# Lower = more detections but more noise, Higher = fewer but more confident detections
SAM_CONFIDENCE_THRESHOLD=0.5

# Component images directory (relative to OUTPUT_DIR)
COMPONENTS_DIR=components

# ========================================
# VECTOR DATABASE (ChromaDB)
# ========================================
CHROMA_PERSIST_DIR=./backend/chroma_db
COLLECTION_NAME=lego_manuals

# ========================================
# BACKEND SERVER
# ========================================
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO

# ========================================
# DATA PATHS
# ========================================
OUTPUT_DIR=./output
TEMP_PAGES_DIR=./output/temp_pages

# ========================================
# RAG PIPELINE SETTINGS
# ========================================
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7
MAX_CONTEXT_LENGTH=4000

# ========================================
# LITELLM TIPS
# ========================================
# 1. You can use ANY model from 100+ providers
# 2. Just add the API key above and specify the model
# 3. See https://docs.litellm.ai/docs/providers for full list
#
# Examples:
#   OpenAI: "gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"
#   Anthropic: "claude-3-5-sonnet-20241022"
#   Gemini: "gemini/gemini-2.5-flash"
#   Cohere: "command-r-plus"
#   Mistral: "mistral/mistral-large-latest"
#   Together AI: "together_ai/meta-llama/Llama-3-70b-chat-hf"
